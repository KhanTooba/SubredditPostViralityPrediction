{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "subredditViralityPrediction-Version1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPz9tfBc9Dbh4swrq9Q9Aoq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prR97OD6TTZD"
      },
      "source": [
        "# This notebook is only to describe the flow of our project.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Helper functions have been implemented in this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ieMEreJyJJ2"
      },
      "source": [
        "\n",
        "\n",
        "def findNodes():\n",
        "\"\"\"\n",
        "findNodes: Reads the authors json file and finds all different users or authors of posts.\n",
        "           They will be depicted as nodes in the graph.\n",
        "           Every node in the graph will have attributed like number of posts (where each post will store the date and time of post, content, number of comments on it, number of upvotes and any other required information about it),\n",
        "           Each node will also store the user_id, the subreddit_id in which it was posted and etc.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def constructGraph():\n",
        "\"\"\"\n",
        "constructGraph: Reads the submissions and comments json files and constructs edges between nodes thus constructing, a graph where each node is a user. \n",
        "                A directed edge from user i to user j i.e [i,j] means that i has commented on a post submitted by j.\n",
        "                It then returns the constructed graph. \n",
        "                Every edge can also be assigned weights depending on the number of comments. If i has commented on k posts of user j, then weight of edge [i,j] will be k.\n",
        "                The implementation of graph i.e adjacency matrix, adjacency list or using a python library is yet to be decided upon.\n",
        "\"\"\"\n",
        "\n",
        "def returnGraph():\n",
        "  \"\"\"\n",
        "  Return the Networkx graph saved in gexf format.\n",
        "  \"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLRoy1tdTZyi"
      },
      "source": [
        "**Helper** functions to find inherent properties of the graph **bold text** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJa-pKG2O93v"
      },
      "source": [
        "\n",
        "\n",
        "def findIndegree(g, indegree):\n",
        "\"\"\"\n",
        "findIndegree: Finds the in-degree of all the nodes in the graph g and stores it in the array indegree.\n",
        "\"\"\"\n",
        "\n",
        "def findOutdegree(g, outdegree):\n",
        "\"\"\"\n",
        "findOutdegree: Finds the out-degree of all the nodes in the graph g and stores it in the array outdegree. \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ0N1gI9TedD"
      },
      "source": [
        "Helper functions to find structural properties of the graph bold text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyDT5FdtO-Az"
      },
      "source": [
        "\n",
        "\n",
        "def findPageRank(g, pageRank):\n",
        "\"\"\"\n",
        "findPageRank: Finds the pageRank of all the nodes in the graph g and stores it in the array pageRank.\n",
        "\"\"\"\n",
        "#G = nx.DiGraph(nx.path_graph(4))\n",
        "#pr = nx.pagerank(G, alpha=0.9)\n",
        "\n",
        "def findHubsAuthority(g, hubs, authority):\n",
        "\"\"\"\n",
        "findHubsAuthority: Finds the hubs and authority score of all the nodes in the graph g and stores it in their respective arrays.\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "    node_list = graph.nodes\n",
        "    #New auth = the sum of the hub of all of its parents\n",
        "    for node in node_list:\n",
        "        node.auth=sum(node.hub for node in node.parents)\n",
        "    #New hub = the sum of the auth of all of its children    \n",
        "    for node in node_list:\n",
        "        node.hub=sum(node.auth for node in node.children)\n",
        "    #normalize auth and hub\n",
        "    auth_sum = sum(node.auth for node in graph.nodes)\n",
        "    hub_sum = sum(node.hub for node in graph.nodes)\n",
        "\n",
        "    for node in graph.nodes:\n",
        "        node.auth /= auth_sum\n",
        "        node.hub /= hub_sum   \n",
        "\"\"\"\n",
        "#nx.hits(G, max_iter=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UMWBkK7Tuot"
      },
      "source": [
        "Helper functions to get the input feature vector for classfier to be trained in next phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSesoo1WRvQI"
      },
      "source": [
        "\n",
        "\n",
        "def getFeatures(g, indegree, outdegree, pageRank, authority):\n",
        "\"\"\"\n",
        "getFeatures: For each post, we store the features like->\n",
        "                                                        1. date time of post\n",
        "                                                        2. Content of the post and a sentiment analysis on it.\n",
        "                                                        3. PageRank, Hubs, authority scores of the author of the post.\n",
        "                                                        4. Indegree, outdgree of the author of the post.\n",
        "                                                        5. Any other attributes that we want to add.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDZjTqPMTxLy"
      },
      "source": [
        "Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdhvtwvyNLXi"
      },
      "source": [
        "def main():\n",
        "\"\"\"\n",
        "Makes the following function calls:\n",
        "1.  Declare a graph object which will be used in the entire code\n",
        "2.  Finds the nodes using findNodes() function\n",
        "3.  Constructs the  graph using constructGraph() function\n",
        "4.  Run the PageRank, Hubs authority algorithms on graph to find structural attributes.\n",
        "5.  We can also find more structural attributes. It will help us get different results.\n",
        "\"\"\"\n",
        "\n",
        "  #graph = make new Graph\n",
        "  findNodes()\n",
        "  constructGraph()\n",
        "\n",
        "  #finding inherent properties\n",
        "  indegree=[]       #array of size n to store indegree of all n nodes\n",
        "  outdegree=[]      #array of size n to store outdegree of all n nodes\n",
        "  findIndegree(graph, indegree)\n",
        "  findOutdegree(graph, outdegree)\n",
        "\n",
        "  #finding structural properties\n",
        "  pageRank=[]       #array of size n to store pageRank of all n nodes\n",
        "  hubs=[]           #array of size n to store hubs scores of all n nodes\n",
        "  authority=[]      #array of size n to store authority scores of all n nodes\n",
        "  findPageRank(graph, pageRank)\n",
        "  findHubsAuthority(graph, hubs, authority)\n",
        "\n",
        "  \"\"\"\n",
        "  Now, we have all the attributed ready for each node. We just have to tranform this information into a feature vector which can be sent to training.\n",
        "  \"\"\"\n",
        "\n",
        "  features=[]       #This will be a faeture vector whose dimentionality will depend on the number of posts and attributes being considered for each post\n",
        "  getFeatures(graph, indegree, outdegree, pageRank, authority)\n",
        "\n",
        "  \"\"\"\n",
        "  This ends the first phase of our project. \n",
        "  In the second phase, we will create a classifier which will be trained on the features extracted by the getFeatures() function.\n",
        "  Prediction is done as x-->y\n",
        "  Here, x will be our feature vector given as input.\n",
        "  Y will be number of upvotes for each post and number of comments on it\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}