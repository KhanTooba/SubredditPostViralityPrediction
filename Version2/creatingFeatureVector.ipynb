{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"creatingFeatureVector.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMn7xZL5uKJaQ9jjgp1uTEd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CATKgUozAs8n"},"source":["import pandas as pd\n","import requests #Pushshift accesses Reddit via an url so this is needed\n","import json #JSON manipulation\n","import csv #To Convert final table into a csv file to save to your machine\n","import time\n","import datetime\n","from tqdm import tqdm\n","import networkx as nx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IP0H16ioA1dv","executionInfo":{"status":"ok","timestamp":1637223059480,"user_tz":-330,"elapsed":58975,"user":{"displayName":"Sna Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07063769688094038673"}},"outputId":"633df152-4b83-48f9-a8b7-5b760073ca34"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!cp -r  /content/gdrive/MyDrive/gaming.csv '/content/'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Czzw80HMA9pq","executionInfo":{"status":"ok","timestamp":1637223074986,"user_tz":-330,"elapsed":15509,"user":{"displayName":"Sna Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07063769688094038673"}},"outputId":"96e1fc77-73af-4a72-a902-f745fdacb11b"},"source":["G=nx.read_gexf('/content/gdrive/MyDrive/gaming_v5.gexf')\n","G_nodes = G.number_of_nodes()\n","G_edges = G.number_of_edges()\n","print(\"Nodes = \", G_nodes, \" Edges = \",G_edges)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nodes =  212842  Edges =  373026\n"]}]},{"cell_type":"code","metadata":{"id":"MlBP6joDBcIa"},"source":["\"\"\"\n","Calculating page rank for all the nodes in the network.\n","\"\"\"\n","pageRank = nx.pagerank(G, alpha=0.9)\n","#print(pageRank)\n","f = open(\"pageRank.txt\", \"a\")\n","for i in pageRank:\n","  x=str(i)+\"-->\"+str(pageRank[str(i)])\n","  f.write(str(x))\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iAebEcMCBCd","executionInfo":{"status":"ok","timestamp":1637223078576,"user_tz":-330,"elapsed":1695,"user":{"displayName":"Sna Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07063769688094038673"}},"outputId":"a3386c82-fb43-4be4-f75e-519722c76e41"},"source":["\"\"\"\n","Calculating degree centrality for all the nodes in the network.\n","\"\"\"\n","degreeCentrality = nx.degree_centrality(G)\n","print(len(degreeCentrality))\n","f = open(\"degreeCentrality.txt\", \"a\")\n","for i in degreeCentrality:\n","  x=str(i)+\"-->\"+str(degreeCentrality[str(i)])\n","  f.write(str(x))\n","f.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["212842\n"]}]},{"cell_type":"code","metadata":{"id":"4D3e4EHcFUtC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637223082540,"user_tz":-330,"elapsed":3967,"user":{"displayName":"Sna Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07063769688094038673"}},"outputId":"8bd5eb89-34be-4b33-e5ca-2b7e920ae308"},"source":["\"\"\"\n","Downloading required package for sentiment analysis.\n","\"\"\"\n","import nltk\n","nltk.download([\"names\",\"stopwords\",\"state_union\",\"twitter_samples\",\"movie_reviews\",\"averaged_perceptron_tagger\",\"vader_lexicon\",\"punkt\"])\n","\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","sia = SentimentIntensityAnalyzer()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package names to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/names.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package state_union to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/state_union.zip.\n","[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/twitter_samples.zip.\n","[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"]}]},{"cell_type":"code","metadata":{"id":"5OfBlzVvGNYD"},"source":["\"\"\"\n","Sentiment Analysis for all the posts in the network.\n","\"\"\"\n","def sentimentScore(sentence):\n","  x=sia.polarity_scores(sentence)\n","  diff=abs(x['pos']-x['neg'])\n","  return 0 if diff<0.01 else 1 if x['pos']>x['neg'] else -1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKbY9OO6Ihjm","executionInfo":{"status":"ok","timestamp":1637223976798,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sna Project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07063769688094038673"}},"outputId":"1e620f34-a701-4c7d-8347-24bebbbbff47"},"source":["print(sentimentScore(\"Wow, NLTK is !\"))\n","print(sentimentScore(\"Wow, I hate love hate NLTK!\"))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n"]}]},{"cell_type":"code","metadata":{"id":"KiyTLVtOMZhD"},"source":["i=0\n","rows=[]\n","for node in G:\n","  listOfdata=(G.nodes[node][\"data\"]).split('{\\'')[1:]\n","  print(i,\"    \",G.nodes[node][\"data\"])\n","  pr=pageRank[str(node)]\n","  dc=degreeCentrality[str(node)]\n","  for l in listOfdata:\n","    print(l)\n","\n","    data=(l).split('PostId\\':')\n","    id1=(data[1].split('\\'Title\\':'))\n","    title1=(id1[1].split('\\'Score\\':'))\n","    score1=(title1[1].split('\\'Date\\':'))\n","    print(score1)\n","    date1=(score1[1].split('\\'Comments\\':'))\n","    postID = id1[0][2:-3]\n","    title = title1[0][2:-3]\n","    score = score1[0][2:-3]\n","    date = date1[0][2:-3]\n","    comments = date1[1][2:-3]\n","    # Below is all the data we require for a given post\n","    sA=sentimentScore(title)\n","    row=[postID,title,date,comments,sA,pr,dc,score]\n","    rows.append(row)\n","    print(\"X-Features---->\",postID,\"   \",title,\"   \",date,\"   \",comments,\"   \",sA,\"   \",pr,\"   \",dc)\n","    print(\"Y-Features---->\",score)\n","  i=i+1\n","  # if i>100:\n","  #   break\n","print(\"Data for \",(i-1),\" posts has been converted to feature vector.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDF6QK7oTeOH"},"source":["filename = \"feature_vector.csv\"\n","\t\n","with open(filename, 'w') as csvfile:\n","\tcsvwriter = csv.writer(csvfile)\n","\tcsvwriter.writerows(rows)"],"execution_count":null,"outputs":[]}]}